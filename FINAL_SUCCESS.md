# Shimmy Dynamic Model Download - FINAL SUCCESS! âœ…

## Status: FULLY OPERATIONAL

Successfully implemented **automatic model download with discovery and server restart** for Shimmy in Kubernetes!

## The Journey: Root Cause Analysis

### The Problem
Models downloaded via `/v1/api/pull` weren't appearing in `/v1/models` endpoint.

### Investigation Steps

1. **Initial Assumption**: Model discovery wasn't running
   - âœ… Discovery WAS running and finding models
   - âŒ Models still not appearing

2. **Second Assumption**: Server needs SIGHUP signal to reload
   - âŒ Shimmy doesn't support hot-reload signals
   - Result: SIGHUP killed the process

3. **Third Attempt**: Use SIGTERM for graceful termination
   - âœ… SIGTERM sent successfully
   - âŒ Models still not appearing

4. **ROOT CAUSE DISCOVERED**: 
   - Analyzed Shimmy source code (`/Users/karthikeyan/git/shimmy/src/main.rs`)
   - **Line 56-57**: `enhanced_state.registry.auto_register_discovered()`
   - **Key Finding**: Shimmy loads models **ONCE at startup** into its registry
   - Models discovered AFTER startup aren't picked up until **restart**

5. **FINAL BUG**: Monitoring script was **exiting** instead of **restarting**
   - When SIGTERM killed Shimmy, the script detected "process died"
   - Called `cleanup()` which killed the proxy too
   - Container exited with code 1
   - **Fix**: Changed monitoring loop to RESTART Shimmy instead of exiting

## Final Solution (v2.6)

**Docker Image**: `docker.io/gjkarthik/shimmy:v2.6-restart-fix` (also `:latest`)

### Key Changes

1. **model-downloader-proxy.py**: 
   - Downloads GGUF from HuggingFace
   - Runs `shimmy discover`
   - Sends SIGTERM to Shimmy process
   - Returns success

2. **start-with-downloader.sh** (THE FIX):
```bash
# OLD - Exited on Shimmy termination
if ! kill -0 $SHIMMY_PID 2>/dev/null; then
    echo "ERROR: Shimmy process died"
    cleanup  # Kills proxy too!
    exit 1
fi

# NEW - Restarts Shimmy automatically
if ! kill -0 $SHIMMY_PID 2>/dev/null; then
    echo "Shimmy process terminated - restarting with new models..."
    shimmy serve --bind 0.0.0.0:8081 --model-path /models &
    SHIMMY_PID=$!
    # Wait for ready...
    echo "Shimmy restarted successfully with new models!"
fi
```

## Complete Workflow (VERIFIED WORKING âœ…)

```
Step 1: Initial State
  GET /v1/models â†’ ["models", "phi3-lora"]

Step 2: Download Model
  POST /v1/api/pull 
  {
    "model": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",
    "filename": "tinyllama-1.1b-chat-v1.0.Q2_K.gguf"
  }
  
  Response:
  {"status": "starting", ...}
  {"status": "complete", "size_mb": 460.74, "discovered": true}

Step 3: Automatic Process (Inside Container)
  1. File downloaded â†’ /models/tinyllama-1.1b-chat-v1.0.Q2_K.gguf âœ…
  2. Discovery runs â†’ shimmy discover âœ…
  3. Find Shimmy PID â†’ pgrep -f 'shimmy serve' âœ…
  4. Send termination â†’ kill -TERM <PID> âœ…
  5. Monitoring detects â†’ Shimmy terminated âœ…
  6. Restart Shimmy â†’ New instance starts âœ…
  7. Auto-discovery runs â†’ Loads ALL models âœ…
  8. Server ready â†’ With new + old models âœ…

Step 4: Verify Model Appears (20 seconds later)
  GET /v1/models â†’ Now includes:
  {
    "id": "tinyllama-1.1b-chat-v1.0.q2-k",
    "object": "model",
    "owned_by": "shimmy"
  }
```

## Test Results

### End-to-End Test (SUCCESS âœ…)

```bash
# Step 1: Check initial models
$ curl http://localhost:8080/v1/models | jq '.data[].id'
"models"
"phi3-lora"

# Step 2: Download TinyLlama
$ curl -X POST http://localhost:8080/v1/api/pull \
  -d '{"model": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF", ...}'
{"status": "starting", ...}
{"status": "complete", "size_mb": 460.74, "discovered": true}

# Step 3: Wait 20 seconds for restart

# Step 4: Model now available!
$ curl http://localhost:8080/v1/models | jq '.data[] | select(.id | contains("tiny"))'
{
  "created": 1768662672,
  "id": "tinyllama-1.1b-chat-v1.0.q2-k",
  "object": "model",
  "owned_by": "shimmy"
}
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Pod: shimmy-model-downloader           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Container: shimmy                                â”‚  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ start-with-downloader.sh (PID 1)            â”‚ â”‚  â”‚
â”‚  â”‚  â”‚                                              â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  While true:                                 â”‚ â”‚  â”‚
â”‚  â”‚  â”‚    If Shimmy died:                          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚      â†’ RESTART Shimmy (not exit!)          â”‚ â”‚  â”‚
â”‚  â”‚  â”‚    If Proxy died:                           â”‚ â”‚  â”‚
â”‚  â”‚  â”‚      â†’ Exit (real error)                    â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚       â”‚                            â”‚              â”‚  â”‚
â”‚  â”‚       â†“                            â†“              â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚   Shimmy    â”‚          â”‚ model-downloader â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   :8081     â”‚â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   proxy.py       â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  (serves    â”‚          â”‚   :8080          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   models)   â”‚          â”‚ (downloads       â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  & restarts)     â”‚  â”‚  â”‚
â”‚  â”‚       â†‘                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚       â”‚                            â†“             â”‚  â”‚
â”‚  â”‚       â”‚                   POST /v1/api/pull     â”‚  â”‚
â”‚  â”‚       â”‚                     1. Download GGUF    â”‚  â”‚
â”‚  â”‚       â”‚                     2. Run discover     â”‚  â”‚
â”‚  â”‚       â”‚                     3. Send SIGTERM     â”‚  â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Restart triggered â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚                                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Deployment

### Current Status

```bash
$ kubectl get pods -n kube-scb -l app=shimmy-model-downloader
NAME                                      READY   STATUS    RESTARTS   AGE
shimmy-model-downloader-<hash>            2/2     Running   0          5m

$ kubectl get svc -n kube-scb shimmy-model-downloader
NAME                      TYPE        CLUSTER-IP      PORT(S)
shimmy-model-downloader   ClusterIP   10.x.x.x        8080/TCP
```

### Configuration

- **Image**: `docker.io/gjkarthik/shimmy:latest` (v2.6)
- **ImagePullPolicy**: `Always`
- **Resources**: 4 CPU, 8Gi RAM
- **Model Path**: `/models` (ephemeral storage)

## API Endpoints

All accessible via port 8080:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Service info |
| `/v1/health` | GET | Health check (SAP AI Core compatible) |
| `/v1/models` | GET | List all models (OpenAI-compatible) |
| `/v1/generate` | POST | Text generation |
| `/v1/completions` | POST | OpenAI-compatible completions |
| `/v1/api/pull` | POST | **Download models from HuggingFace** |

## Usage Examples

### Download a Model

```bash
curl -X POST http://localhost:8080/v1/api/pull \
  -H "Content-Type: application/json" \
  -d '{
    "model": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",
    "filename": "tinyllama-1.1b-chat-v1.0.Q2_K.gguf"
  }'
```

### Wait for Restart

The server automatically restarts. Wait ~20-30 seconds.

### Verify Model Available

```bash
curl http://localhost:8080/v1/models | \
  jq '.data[] | select(.id | contains("tiny"))'
```

### Test Inference

```bash
curl -X POST http://localhost:8080/v1/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tinyllama-1.1b-chat-v1.0.q2-k",
    "prompt": "Hello! Introduce yourself.",
    "max_tokens": 50
  }' | jq '.response'
```

## Lessons Learned

1. **Always check source code** - The Shimmy source revealed the startup-only loading
2. **Monitor scripts need restart logic** - Don't just exit on process termination
3. **Test the complete workflow** - End-to-end testing caught the restart issue
4. **SIGTERM is better than SIGHUP** - More universal for graceful termination
5. **Ephemeral storage is okay for testing** - But add PVC for production

## Known Limitations

1. **Ephemeral Storage**: Models lost on pod restart
   - **Solution**: Add PersistentVolumeClaim for `/models`

2. **Restart Downtime**: ~20-30 seconds during model loading
   - **Acceptable**: For model management operations
   - Models remain available via other replicas in multi-replica setup

3. **Single Download**: Only one download at a time
   - Protected by lock in proxy
   - Concurrent requests return 409 Conflict

## Production Recommendations

### 1. Add Persistent Storage

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: shimmy-models
  namespace: kube-scb
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
```

Update deployment:
```yaml
volumes:
  - name: models
    persistentVolumeClaim:
      claimName: shimmy-models
volumeMounts:
  - name: models
    mountPath: /models
```

### 2. Model Size Planning

| Model Type | Quantization | Size | Storage Needed |
|------------|-------------|------|----------------|
| Tiny | Q2_K | 400-500MB | 10Gi |
| Small | Q4_K_M | 1-2GB | 20Gi |
| Medium | Q5_K_M | 3-5GB | 30Gi |
| Large | Q8_0 | 7-10GB | 50Gi |

### 3. Multi-Replica Setup

For zero-downtime:
```yaml
spec:
  replicas: 2  # One stays up during restart
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 1
```

## Version History

| Version | Changes | Status |
|---------|---------|--------|
| v2.2 | Fixed model path | âœ… |
| v2.3 | Added SIGHUP restart | âŒ Killed Shimmy |
| v2.4 | Added procps package | âŒ Still using SIGHUP |
| v2.5 | Changed to SIGTERM | âŒ Script exited |
| v2.6 | **Fixed restart loop** | âœ… **WORKING** |

## Files Modified

1. `model-downloader-proxy.py` - Download API with discovery
2. `start-with-downloader.sh` - **Restart loop fix**
3. `Dockerfile.rbac-fix-with-pull` - Production Dockerfile
4. `deployment-with-pull.yaml` - Kubernetes deployment
5. `service-with-pull.yaml` - Kubernetes service

## Success Metrics

- âœ… **Implementation**: 100% Complete
- âœ… **Download API**: Working
- âœ… **Model Discovery**: Working  
- âœ… **Server Restart**: Working
- âœ… **Model Registration**: Working
- âœ… **End-to-End Test**: **PASSED** âœ…

## Conclusion

The Shimmy dynamic model download feature is **fully operational**! 

The key was understanding that:
1. Shimmy loads models ONCE at startup
2. Server restart is required for new models
3. Monitoring script must RESTART, not EXIT

**Production Image**: `docker.io/gjkarthik/shimmy:v2.6-restart-fix`

Ready for production use with persistent storage! ğŸš€ğŸ‰
